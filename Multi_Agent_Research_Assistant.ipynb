{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-Agent Research Assistant\n",
        "**This assistant involves a multi-agent system for browsing, analyzing, and summarizing research papers.**\n",
        "\n",
        "### Features:\n",
        "- *Document Retrieval*: Downloading research papers in PDF format from provided URLs.\n",
        "- *Text Extraction*: Extracting specific sections such as the title, abstract, methods, and conclusions.\n",
        "- *Summarization*: Automatically retrieving key sections of the paper.\n",
        "\n",
        "\n",
        "### Instructions:\n",
        "1. Enter the topic of the research papers you are looking for\n",
        "2. Choose which sections to extract.\n",
        "3. View the extracted sections as output.\n",
        "4. Get the summary of the required section."
      ],
      "metadata": {
        "id": "wxxSuOtYMD6F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "2rmfivuoWWBt",
        "outputId": "1faaa312-b660-407f-898d-491ab6514b34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the topic you want to search for: machine learning\n",
            "Do you want to apply filters (yes/no)? no\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Published Date</th>\n",
              "      <th>PDF Link</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Lecture Notes: Optimization for Machine Learning</td>\n",
              "      <td>2019-09-08T21:49:42Z</td>\n",
              "      <td><a href=\"http://arxiv.org/pdf/1909.03550v1\" target=\"_blank\">Download PDF</a></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>An Optimal Control View of Adversarial Machine Learning</td>\n",
              "      <td>2018-11-11T14:28:34Z</td>\n",
              "      <td><a href=\"http://arxiv.org/pdf/1811.04422v1\" target=\"_blank\">Download PDF</a></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Minimax deviation strategies for machine learning and recognition with\\n  short learning samples</td>\n",
              "      <td>2017-07-16T09:15:08Z</td>\n",
              "      <td><a href=\"http://arxiv.org/pdf/1707.04849v1\" target=\"_blank\">Download PDF</a></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Machine Learning for Clinical Predictive Analytics</td>\n",
              "      <td>2019-09-19T22:02:00Z</td>\n",
              "      <td><a href=\"http://arxiv.org/pdf/1909.09246v1\" target=\"_blank\">Download PDF</a></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Towards Modular Machine Learning Solution Development: Benefits and\\n  Trade-offs</td>\n",
              "      <td>2023-01-23T22:54:34Z</td>\n",
              "      <td><a href=\"http://arxiv.org/pdf/2301.09753v1\" target=\"_blank\">Download PDF</a></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Introduction to Machine Learning: Class Notes 67577</td>\n",
              "      <td>2009-04-23T11:40:57Z</td>\n",
              "      <td><a href=\"http://arxiv.org/pdf/0904.3664v1\" target=\"_blank\">Download PDF</a></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>The Tribes of Machine Learning and the Realm of Computer Architecture</td>\n",
              "      <td>2020-12-07T23:10:51Z</td>\n",
              "      <td><a href=\"http://arxiv.org/pdf/2012.04105v1\" target=\"_blank\">Download PDF</a></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>A Machine Learning Tutorial for Operational Meteorology, Part I:\\n  Traditional Machine Learning</td>\n",
              "      <td>2022-04-15T14:48:04Z</td>\n",
              "      <td><a href=\"http://arxiv.org/pdf/2204.07492v2\" target=\"_blank\">Download PDF</a></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Position Paper: Towards Transparent Machine Learning</td>\n",
              "      <td>2019-11-12T10:49:55Z</td>\n",
              "      <td><a href=\"http://arxiv.org/pdf/1911.06612v1\" target=\"_blank\">Download PDF</a></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Understanding Bias in Machine Learning</td>\n",
              "      <td>2019-09-02T20:36:19Z</td>\n",
              "      <td><a href=\"http://arxiv.org/pdf/1909.01866v1\" target=\"_blank\">Download PDF</a></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import requests\n",
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "# Function to fetch data from arXiv API with or without filters\n",
        "def fetch_research_papers(query, start_date=None, end_date=None, max_results=10):\n",
        "    base_url = \"http://export.arxiv.org/api/query?\"\n",
        "    api_url = f\"{base_url}search_query=all:{query}&start=0&max_results={max_results}\"\n",
        "\n",
        "    if start_date and end_date:\n",
        "        api_url += f\"&start_date={start_date}&end_date={end_date}\"\n",
        "\n",
        "    response = requests.get(api_url)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        return response.content  # Return XML content\n",
        "    else:\n",
        "        print(f\"Failed to retrieve data. Status code: {response.status_code}\")\n",
        "        return None\n",
        "\n",
        "# Function to display results in a table with clickable PDF links\n",
        "def display_research_papers_in_table(xml_data):\n",
        "    root = ET.fromstring(xml_data)\n",
        "\n",
        "    titles = []\n",
        "    published_dates = []\n",
        "    pdf_links = []\n",
        "    pdf_urls=[]\n",
        "\n",
        "    for entry in root.findall('{http://www.w3.org/2005/Atom}entry'):\n",
        "        title = entry.find('{http://www.w3.org/2005/Atom}title').text\n",
        "        published_date = entry.find('{http://www.w3.org/2005/Atom}published').text\n",
        "\n",
        "        # Look for the PDF link\n",
        "        pdf_link = None\n",
        "        for link in entry.findall('{http://www.w3.org/2005/Atom}link'):\n",
        "            if link.get('type') == 'application/pdf':\n",
        "                pdf_link = link.get('href')\n",
        "                pdf_urls.append(pdf_link)\n",
        "                break\n",
        "\n",
        "        if pdf_link:\n",
        "            pdf_links.append(f'<a href=\"{pdf_link}\" target=\"_blank\">Download PDF</a>')\n",
        "        else:\n",
        "            pdf_links.append('No PDF available')\n",
        "\n",
        "        titles.append(title)\n",
        "        published_dates.append(published_date)\n",
        "\n",
        "    df = pd.DataFrame({\n",
        "        \"Title\": titles,\n",
        "        \"Published Date\": published_dates,\n",
        "        \"PDF Link\": pdf_links\n",
        "    })\n",
        "\n",
        "    display(HTML(df.to_html(escape=False)))\n",
        "\n",
        "    return pdf_urls\n",
        "\n",
        "# Main function to ask user for input and handle filters\n",
        "def main():\n",
        "    query = input(\"Enter the topic you want to search for: \")\n",
        "    apply_filters = input(\"Do you want to apply filters (yes/no)? \").lower()\n",
        "\n",
        "    if apply_filters == \"yes\":\n",
        "        start_date = input(\"Enter the start date (YYYY-MM-DD): \")\n",
        "        end_date = input(\"Enter the end date (YYYY-MM-DD): \")\n",
        "        max_results = input(\"Enter the number of research papers to retrieve: \")\n",
        "\n",
        "        xml_data = fetch_research_papers(query, start_date=start_date, end_date=end_date, max_results=max_results)\n",
        "    else:\n",
        "        xml_data = fetch_research_papers(query)\n",
        "\n",
        "    if xml_data:\n",
        "      pdf_urls= display_research_papers_in_table(xml_data)\n",
        "      return pdf_urls\n",
        "\n",
        "    if not xml_data:\n",
        "     print(\"No data returned from arXiv.\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    pdf_urls= main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2 pdfplumber"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPgPy_1gXAR4",
        "outputId": "743ac291-09ef-4ff6-82f7-c949d7a65e95",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.4-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdfminer.six==20231228 (from pdfplumber)\n",
            "  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (9.4.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.3.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (43.0.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfplumber-0.11.4-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.2/59.2 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdfium2, PyPDF2, pdfminer.six, pdfplumber\n",
            "Successfully installed PyPDF2-3.0.1 pdfminer.six-20231228 pdfplumber-0.11.4 pypdfium2-4.30.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfplumber\n",
        "import re\n",
        "import requests\n",
        "\n",
        "\n",
        "# Function to download the PDF from a URL\n",
        "def download_pdf(url, file_name):\n",
        "    response = requests.get(url)\n",
        "    with open(file_name, 'wb') as f:\n",
        "        f.write(response.content)\n",
        "\n",
        "# Function to extract the 'Abstract' section from the PDF\n",
        "def extract_abstract_from_pdf(file_path):\n",
        "    with pdfplumber.open(file_path) as pdf:\n",
        "        # Loop through all pages to find the abstract\n",
        "        text = ''\n",
        "        for page in pdf.pages:\n",
        "            text += page.extract_text()\n",
        "\n",
        "        # Use a regex pattern to find the abstract section\n",
        "        # This assumes 'Abstract' is a heading and followed by text\n",
        "        abstract_pattern = re.compile(r\"(?i)(abstract[\\s\\S]*?)(introduction|background|keywords|1\\.|2\\.|section\\s\\d)\", re.IGNORECASE)\n",
        "        match = abstract_pattern.search(text)\n",
        "\n",
        "        if match:\n",
        "            return match.group(1).strip()\n",
        "        else:\n",
        "            return \"Abstract not found.\"\n",
        "\n",
        "# Check if pdf_urls was fetched successfully\n",
        "if 'pdf_urls' in globals():\n",
        "    # Loop through each PDF link\n",
        "    for i, url in enumerate(pdf_urls):\n",
        "        file_name = f\"paper_{i+1}.pdf\"\n",
        "\n",
        "        # Download the PDF\n",
        "        download_pdf(url, file_name)\n",
        "\n",
        "        # Extract the abstract\n",
        "        abstract = extract_abstract_from_pdf(file_name)\n",
        "\n",
        "        print(f\"Abstract from {file_name}:\")\n",
        "        print(abstract)\n",
        "        print(\"\\n\")\n",
        "else:\n",
        "    print(\"No PDF URLs were found.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ysg9duTWute",
        "outputId": "3c9d55f3-d3e2-4ae2-9ae9-7c1e94f25eb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Abstract from paper_1.pdf:\n",
            "Abstract not found.\n",
            "\n",
            "\n",
            "Abstract from paper_2.pdf:\n",
            "Abstract\n",
            "Idescribeanoptimalcontrolviewofadversarialmachinelearning,wherethedynamicalsystemisthe\n",
            "machine learner, the input are adversarial actions, and the control costs are defined by the adversary’s\n",
            "goals to do harm and be hard to detect. This view encompasses many types of adversarial machine\n",
            "learning,includingtest-itemattacks,training-datapoisoning, andadversarial rewardshaping. Theview\n",
            "encouragesadversarialmachinelearningresearchertoutilizeadvancesincontroltheoryandreinforcement\n",
            "learning.\n",
            "1 Adversarial Machine Learning is not Machine Learning\n",
            "Machine learning has its mathematical foundation in concentration inequalities. This is a consequence of\n",
            "the independent and identically-distributed (i.i.d.) data assumption. In contrast, I suggest that adversarial\n",
            "machine learning may adopt optimal controlas its mathematical foundation [3,25]. There are telltale signs:\n",
            "adversarialattacks tend to be subtle and have peculiar non-i.i.d. structures – as control input might be.\n",
            "2 Optimal Control\n",
            "I will focus on deterministic discrete-time optimal control because it matches many existing adversarial\n",
            "attacks. Extensions to stochastic and continuous control are relevant to adversarial machine learning, too.\n",
            "The system to be controlled is called the plant, which is defined by the system dynamics:\n",
            "x =f(x ,u ) (1)\n",
            "t+1 t t\n",
            "where x ∈ X is the state of the system, u ∈ U is the control input, and U is the control constraint\n",
            "t t t t t\n",
            "set. The function f defines the evolution of state under external control. The time index t ranges from 0\n",
            "to T −1, and the time horizon T can be finite or infinite. The quality of control is specified by the running\n",
            "cost:\n",
            "g (x ,u ) (2)\n",
            "t t t\n",
            "which defines the step-by-step control cost, and the terminal cost for finite horizon:\n",
            "g (x ) (3)\n",
            "T T\n",
            "whichdefinesthe qualityofthe finalstate. The optimalcontrolproblemistofindcontrolinputs u 0...u T−1\n",
            "in order to minimize the objective:\n",
            "T−1\n",
            "min g (x )+ g (x ,u ) (4)\n",
            "T T t t t\n",
            "u 0...uT−1\n",
            "Xt=0\n",
            "s.t. x =f(x ,u ), u ∈U , ∀t\n",
            "t+1 t t t t\n",
            "x given\n",
            "0\n",
            "1More generally,the controlleraims to find controlpolicies φ (x )=u , namely functions that map observed\n",
            "t t t\n",
            "states to inputs. In optimal control the dynamics f is known to the controller. There are two styles of\n",
            "solutions: dynamic programming and Pontryaginminimum principle [2,10,17]. When f is not fully known,\n",
            "theproblembecomeseitherrobustcontrolwherecontroliscarriedoutinaminimaxfashiontoaccommodate\n",
            "the worst case dynamics [28], or reinforcement learning where the controller probes the dynamics [23].\n",
            "3 Adversarial Machine Learning as Control\n",
            "Now let us translate adversarial machine learning into a control formulation. Adversarial machine learning\n",
            "studies vulnerability throughout the learning pipeline [4,13,20,26]. As examples, I present training-data\n",
            "poisoning, test-time attacks, and adversarial reward shaping below. In all cases, the adversary attempts to\n",
            "control the machine learning system, and the control costs reflect the adversary’s desire to do harm and be\n",
            "hard to detect.\n",
            "Unfortunately, the notations from the control community and the machine learning community clash.\n",
            "Forexample,xdenotesthestateincontrolbutthefeaturevectorinmachinelearning. Iwillusethemachine\n",
            "learning convention below.\n",
            "3.1 Training-Data Poisoning\n",
            "In training-data poisoning the adversary can modify the training data. The machine learner then trains a\n",
            "“wrong”modelfromthe poisoneddata. Theadversary’sgoalisforthe “wrong”modeltobe usefulforsome\n",
            "nefarious purpose. I use supervised learning for illustration.\n",
            "3.\n",
            "\n",
            "\n",
            "Abstract from paper_3.pdf:\n",
            "Abstract\n",
            "The article is devoted to the problem of small learning samples in\n",
            "machinelearning. Theflawsof maximumlikelihood learningandmin-\n",
            "imax learning are looked into and the concept of minimax deviation\n",
            "learning is introduced that is free of those flaws.\n",
            "1\n",
            "\n",
            "\n",
            "Abstract from paper_4.pdf:\n",
            "Abstract not found.\n",
            "\n",
            "\n",
            "Abstract from paper_5.pdf:\n",
            "ABSTRACT\n",
            "Machinelearningtechnologieshavedemonstratedimmensecapabilitiesinvariousdomains. Theyplayakey\n",
            "role in the success of modern businesses. However, adoption of machine learning technologies has a lot of\n",
            "untouchedpotential. Costofdevelopingcustommachinelearningsolutionsthatsolveuniquebusinessproblems\n",
            "isamajorinhibitortofar-reachingadoptionofmachinelearningtechnologies. Werecognizethatthemonolithic\n",
            "nature prevalent in today’s machine learning applications stands in the way of efficient and cost effective\n",
            "customizedmachinelearningsolutiondevelopment. Inthisworkweexplorethebenefitsofmodularmachine\n",
            "learningsolutionsanddiscusshowmodularmachinelearningsolutionscanovercomesomeofthemajorsolution\n",
            "engineeringlimitationsofmonolithicmachinelearningsolutions. Weanalyzethetrade-offsbetweenmodularand\n",
            "monolithicmachinelearningsolutionsthroughthreedeeplearningproblems;onetextbasedandthetwoimage\n",
            "based. Ourexperimentalresultsshowthatmodularmachinelearningsolutionshaveapromisingpotentialtoreap\n",
            "thesolutionengineeringadvantagesofmodularitywhilegainingperformanceanddataadvantagesinawaythe\n",
            "monolithicmachinelearningsolutionsdonotpermit.\n",
            "1\n",
            "\n",
            "\n",
            "Abstract from paper_6.pdf:\n",
            "Abstract not found.\n",
            "\n",
            "\n",
            "Abstract from paper_7.pdf:\n",
            "Abstract not found.\n",
            "\n",
            "\n",
            "Abstract from paper_8.pdf:\n",
            "ABSTRACT: Recently,theuseofmachinelearninginmeteorologyhasincreasedgreatly. Whilemanymachinelearningmethodsarenot\n",
            "new,universityclassesonmachinelearningarelargelyunavailabletometeorologystudentsandarenotrequiredtobecomeameteorologist.\n",
            "Thelackofformalinstructionhascontributedtoperceptionthatmachinelearningmethodsare’blackboxes’andthusend-usersarehesitant\n",
            "toapplythemachinelearningmethodsintheireverydayworkflow. Toreducetheopaquenessofmachinelearningmethodsandlower\n",
            "hesitancytowardsmachinelearninginmeteorology,thispaperprovidesasurveyofsomeofthemostcommonmachinelearningmethods.\n",
            "Afamiliarmeteorologicalexampleisusedtocontextualizethemachinelearningmethodswhilealsodiscussingmachinelearningtopics\n",
            "usingplainlanguage. Thefollowingmachinelearningmethodsaredemonstrated: linearregression;logisticregression;decisiontrees;\n",
            "randomforest;gradientboosteddecisiontrees;naïveBayes;andsupportvectormachines. Beyonddiscussingthedifferentmethods,the\n",
            "paperalsocontainsdiscussionsonthegeneralmachinelearningprocessaswellasbestpracticestoenablereaderstoapplymachinelearning\n",
            "totheirowndatasets. Furthermore,allcode(intheformofJupyternotebooksandGoogleColaboratorynotebooks)usedtomakethe\n",
            "examplesinthepaperisprovidedinanefforttocatalysetheuseofmachinelearninginmeteorology.\n",
            "\n",
            "\n",
            "Abstract from paper_9.pdf:\n",
            "Abstract\n",
            "Transparent machine learning is introduced as an alternative form of\n",
            "machinelearning, whereboththemodel andthelearning system arerep-\n",
            "resented in source code form. The goal of this project is to enable direct\n",
            "humanunderstandingofmachinelearningmodels,givingustheabilityto\n",
            "learn,verify,andrefinethemasprograms. Ifsolved,thistechnologycould\n",
            "represent a best-case scenario for the safety and security of AI systems\n",
            "going forward.\n",
            "1\n",
            "\n",
            "\n",
            "Abstract from paper_10.pdf:\n",
            "Abstract. Biasisknowntobeanimpedimenttofairdecisionsinmany\n",
            "domainssuchashumanresources,thepublicsector,healthcareetc.Re-\n",
            "cently,hopehasbeenexpressedthattheuseofmachinelearningmethods\n",
            "fortakingsuchdecisionswoulddiminishorevenresolvetheproblem.At\n",
            "the same time, machine learning experts warn that machine learning\n",
            "models can be biased as well.\n",
            "Inthisarticle,ourgoalistoexplaintheissueofbiasinmachinelearning\n",
            "fromatechnicalperspectiveandtoillustratetheimpactthatbiaseddata\n",
            "canhaveonamachinelearningmodel.Toreachsuchagoal,wedevelop\n",
            "interactiveplotstovisualizingthebiaslearnedfromsyntheticdata.The\n",
            "interactive plots are available\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XiqSGm-l8yHP",
        "outputId": "71e6412c-0ddc-4bf8-d8d7-0cf696e13b82",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.6)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "from IPython.display import display, HTML\n",
        "import pdfplumber\n",
        "import re\n",
        "\n",
        "# Function to download the PDF from a URL\n",
        "def download_pdf(url, file_name):\n",
        "    response = requests.get(url)\n",
        "    with open(file_name, 'wb') as f:\n",
        "        f.write(response.content)\n",
        "\n",
        "\n",
        "# Function to extract a specific section from the PDF\n",
        "def extract_section_from_pdf(file_path, section):\n",
        "    with pdfplumber.open(file_path) as pdf:\n",
        "        # Extract all text from the PDF\n",
        "        text = ''\n",
        "        for page in pdf.pages:\n",
        "            text += page.extract_text()\n",
        "\n",
        "        # Dictionary of regex patterns for various sections\n",
        "        section_patterns = {\n",
        "\n",
        "            \"abstract\": r\"(?i)(?:abstract)\\b[\\s\\S]*?(?=\\b(?:introduction|methods|results|literature review|conclusion|references)\\b)\",\n",
        "            \"introduction\": r\"(?i)(?:introduction)\\b[\\s\\S]*?(?=\\b(?:methods|results|literature review|conclusion|references)\\b)\",\n",
        "            \"methods\": r\"(?i)(?:methods)\\b[\\s\\S]*?(?=\\b(?:results|discussion|conclusion|references)\\b)\",\n",
        "            \"results\": r\"(?i)(?:results)\\b[\\s\\S]*?(?=\\b(?:discussion|conclusion|references)\\b)\",\n",
        "            \"literature review\": r\"(?i)(?:literature review)\\b[\\s\\S]*?(?=\\b(?:methods|results|conclusion|references)\\b)\",\n",
        "            \"conclusion\": r\"(?i)(?:conclusion)\\b[\\s\\S]*?(?=\\b(?:references|bibliography|limitations|future scope)\\b)\",\n",
        "            \"bibliography\": r\"(?i)(?:references)\\b[\\s\\S]*?(?=\\b(?:appendix|bibliography|limitations)\\b)\",\n",
        "            \"future scope\": r\"(?i)(?:future scope)\\b[\\s\\S]*?(?=\\b(?:conclusion|bibliography|limitations)\\b)\",\n",
        "            \"limitations\": r\"(?i)(?:limitations)\\b[\\s\\S]*?(?=\\b(?:future work|conclusion|bibliography)\\b)\"\n",
        "        }\n",
        "\n",
        "        # Use the corresponding regex pattern for the requested section\n",
        "        pattern = section_patterns.get(section.lower(), None)\n",
        "        if pattern:\n",
        "            match = re.search(pattern, text)\n",
        "            if match:\n",
        "                return match.group(0).strip()\n",
        "            else:\n",
        "                return f\"{section.capitalize()} not found in this paper.\"\n",
        "        else:\n",
        "           return \"Invalid section selected.\"\n",
        "\n",
        "def summarize_long_text(long_text, model, max_token_length=1024):\n",
        "    # Split the text into chunks smaller than the model's maximum token length\n",
        "    words = long_text.split()\n",
        "    chunks = [' '.join(words[i:i + max_token_length]) for i in range(0, len(words), max_token_length)]\n",
        "\n",
        "    # Summarize each chunk\n",
        "    summarized_chunks = [model(chunk) for chunk in chunks]\n",
        "\n",
        "    # Combine the summaries\n",
        "    return \" \".join(summarized_chunks)\n",
        "\n",
        "# List of PDF URLs\n",
        "if 'pdf_urls' in globals():\n",
        "    # Loop through each PDF link\n",
        "    for i, url in enumerate(pdf_urls):\n",
        "        file_name = f\"paper_{i+1}.pdf\"\n",
        "\n",
        "        # Download the PDF\n",
        "        download_pdf(url, file_name)\n",
        "\n",
        "\n",
        "# List of sections available for extraction\n",
        "available_sections = [\n",
        "     \"abstract\", \"introduction\", \"methods\", \"results\",\n",
        "    \"literature review\", \"conclusion\", \"bibliography\", \"future scope\", \"limitations\"\n",
        "]\n",
        "\n",
        "# Main function to download PDFs and extract sections based on user input\n",
        "def main():\n",
        "    # Ask the user which sections to extract\n",
        "    selected_sections = input(f\"Which sections do you want to extract? (Options: {', '.join(available_sections)})\\nEnter sections separated by commas: \").lower().split(\",\")\n",
        "    selected_sections = [section.strip() for section in selected_sections]\n",
        "\n",
        "     # Dictionary to store extracted sections\n",
        "    extracted_data = {section: [] for section in selected_sections}\n",
        "\n",
        "\n",
        "\n",
        "    # Loop through each PDF link\n",
        "    for i, url in enumerate(pdf_urls):\n",
        "        file_name = f\"paper_{i+1}.pdf\"\n",
        "\n",
        "        # Download the PDF\n",
        "        download_pdf(url, file_name)\n",
        "\n",
        "        # Extract and display the requested sections\n",
        "        print(f\"\\nExtracted sections from {file_name}:\")\n",
        "        for section in selected_sections:\n",
        "            if section in available_sections:\n",
        "                extracted_text = extract_section_from_pdf(file_name, section)\n",
        "                extracted_data[section].append(extracted_text)\n",
        "                #print(f\"\\n--- {section.capitalize()} ---\")\n",
        "                #print(extracted_text)\n",
        "            #else:\n",
        "              #  print(f\"\\n--- {section.capitalize()} ---\")\n",
        "               # print(\"Invalid section. Skipping...\")\n",
        "\n",
        "        for section in selected_sections:\n",
        "            print(f\"\\n--- Summarizing {section.capitalize()} ---\")\n",
        "            combined_text = \" \".join(extracted_data[section])\n",
        "            summarized_text = summarize_text(combined_text)\n",
        "            print(summarized_text)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "ahy34soPZvyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Initialize the summarization pipeline\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "combined_text = \" \".join(all_extracted_texts_from_pdfs)\n",
        "\n",
        "# Function to summarize text\n",
        "def summarize_text(text, max_length=150, min_length=40):\n",
        "    summary = summarizer(combined_text, max_length=max_length, min_length=min_length, do_sample=False)[0]['summary_text']\n",
        "    return summary[0]['summary_text']\n",
        "\n",
        "summary = summarize_text(extracted_text)\n",
        "\n",
        "print(\"Original Text:\")\n",
        "print(extracted_text)\n",
        "print(\"\\nSummarized Text:\")\n",
        "print(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0pH34ACXfq1",
        "outputId": "aae22b54-8d75-4f7c-96ee-5238e4321794"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text:\n",
            "This work is part of an innovative e-learning project allowing\n",
            "the development of an advanced digital educational tool that provides\n",
            "feedback during the process of learning handwriting for young school\n",
            "children (three to eight years old). In this paper, we describe a new method\n",
            "for children handwriting quality analysis. It automatically detects mistakes,\n",
            "gives real-time on-line feedback for children’s writing, and helps teachers\n",
            "comprehend and evaluate children’s writing skills. The proposed method\n",
            "adjudges five main criteria: shape, direction, stroke order, position respect\n",
            "to the reference lines, and kinematics of the trace. It analyzes the\n",
            "handwriting quality and automatically gives feedback based on the\n",
            "combination of three extracted models: Beta-Elliptic Model (BEM) using\n",
            "similarity detection (SD) and dissimilarity distance (DD) measure, Fourier\n",
            "Descriptor Model (FDM), and perceptive Convolutional Neural Network\n",
            "(CNN) with Support Vector Machine (SVM) comparison engine. The\n",
            "originality of our work lies partly in the system architecture which\n",
            "apprehends complementary dynamic, geometric, and visual representation\n",
            "of the examined handwritten scripts and in the efficient selected features\n",
            "adapted to various handwriting styles and multiple script languages such as\n",
            "Arabic, Latin, digits, and symbol drawing. The application offers two\n",
            "interactive interfaces respectively dedicated to learners, educators, experts\n",
            "or teachers and allows them to adapt it easily to the specificity of their\n",
            "disciples. The evaluation of our framework is enhanced by a database\n",
            "collected in Tunisia primary school with 400 children. Experimental results\n",
            "show the efficiency and robustness of our suggested framework that helps\n",
            "teachers and children by offering positive feedback throughout the\n",
            "handwriting learning process using tactile digital devices. \n",
            "\n",
            "Summarized Text:\n",
            "New method for children handwriting quality analysis. It automatically detects mistakes, gives real-time on-line feedback for children’s writing, and helps teachers evaluate writing skills. The application offers two interactive interfaces dedicated to learners, educators, experts, and teachers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfplumber\n",
        "import re\n",
        "import requests\n",
        "from transformers import PegasusTokenizer, PegasusForConditionalGeneration\n",
        "import torch\n",
        "\n",
        "# Function to download the PDF from a URL\n",
        "def download_pdf(url, file_name):\n",
        "    response = requests.get(url)\n",
        "    with open(file_name, 'wb') as f:\n",
        "        f.write(response.content)\n",
        "\n",
        "\n",
        "# Function to extract a specific section from the PDF\n",
        "def extract_section_from_pdf(file_path, section):\n",
        "    with pdfplumber.open(file_path) as pdf:\n",
        "        # Extract all text from the PDF\n",
        "        text = ''\n",
        "        for page in pdf.pages:\n",
        "            page_text = page.extract_text()\n",
        "            if page_text:\n",
        "                text += page_text\n",
        "\n",
        "        # Dictionary of regex patterns for various sections\n",
        "        section_patterns = {\n",
        "            \"abstract\": r\"(?i)(?:abstract)\\b[\\s\\S]*?(?=\\b(?:introduction|methods|results|literature review|conclusion|references)\\b)\",\n",
        "            \"introduction\": r\"(?i)(?:introduction)\\b[\\s\\S]*?(?=\\b(?:methods|results|literature review|conclusion|references)\\b)\",\n",
        "            \"methods\": r\"(?i)(?:methods)\\b[\\s\\S]*?(?=\\b(?:results|discussion|conclusion|references)\\b)\",\n",
        "            \"results\": r\"(?i)(?:results)\\b[\\s\\S]*?(?=\\b(?:discussion|conclusion|references)\\b)\",\n",
        "            \"literature review\": r\"(?i)(?:literature review)\\b[\\s\\S]*?(?=\\b(?:methods|results|conclusion|references)\\b)\",\n",
        "            \"conclusion\": r\"(?i)(?:conclusion)\\b[\\s\\S]*?(?=\\b(?:references|bibliography|limitations|future scope)\\b)\",\n",
        "            \"bibliography\": r\"(?i)(?:references)\\b[\\s\\S]*?(?=\\b(?:appendix|bibliography|limitations)\\b)\",\n",
        "            \"future scope\": r\"(?i)(?:future scope)\\b[\\s\\S]*?(?=\\b(?:conclusion|bibliography|limitations)\\b)\",\n",
        "            \"limitations\": r\"(?i)(?:limitations)\\b[\\s\\S]*?(?=\\b(?:future work|conclusion|bibliography)\\b)\"\n",
        "        }\n",
        "\n",
        "        # Use the corresponding regex pattern for the requested section\n",
        "        pattern = section_patterns.get(section.lower(), None)\n",
        "        if pattern:\n",
        "            match = re.search(pattern, text)\n",
        "            if match:\n",
        "                return match.group(0).strip()\n",
        "            else:\n",
        "                return f\"{section.capitalize()} not found in this paper.\"\n",
        "        else:\n",
        "           return \"Invalid section selected.\"\n",
        "tokenizer = PegasusTokenizer.from_pretrained('google/pegasus-large')\n",
        "model = PegasusForConditionalGeneration.from_pretrained('google/pegasus-large', ignore_mismatched_sizes=True)\n",
        "\n",
        "# Function to summarize the text using Pegasus\n",
        "def summarize_long_text(long_text, max_token_length=1024):\n",
        "\n",
        "    if len(long_text.strip()) == 0:\n",
        "        return \"The section is empty or not found.\"\n",
        "\n",
        "    # Tokenize the text for Pegasus\n",
        "    inputs = tokenizer(long_text, return_tensors=\"pt\", max_length=max_token_length, truncation=True)\n",
        "\n",
        "    # Adjust max_length based on input size if needed\n",
        "    input_length = len(inputs['input_ids'][0])\n",
        "    max_summary_length = min(150, input_length // 2)\n",
        "\n",
        "    # Generate summary\n",
        "    summary_ids = model.generate(inputs['input_ids'], max_length=max_summary_length)\n",
        "\n",
        "    # Decode summary\n",
        "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "\n",
        "# List of sections available for extraction\n",
        "available_sections = [\n",
        "    \"abstract\", \"introduction\", \"methods\", \"results\",\n",
        "    \"literature review\", \"conclusion\", \"bibliography\", \"future scope\", \"limitations\"\n",
        "]\n",
        "\n",
        "\n",
        "# Main function to download PDFs and extract sections based on user input\n",
        "def main():\n",
        "    # Example list of URLs for PDF files\n",
        "    pdf_urls = [\n",
        "        'https://arxiv.org/pdf/2104.03602.pdf',\n",
        "        # Add more URLs if needed\n",
        "    ]\n",
        "\n",
        "    # Ask the user which sections to extract\n",
        "    selected_sections = input(f\"Which sections do you want to extract? (Options: {', '.join(available_sections)})\\nEnter sections separated by commas: \").lower().split(\",\")\n",
        "    selected_sections = [section.strip() for section in selected_sections]\n",
        "\n",
        "    # Dictionary to store extracted sections\n",
        "    extracted_data = {section: [] for section in selected_sections}\n",
        "\n",
        "    # Loop through each PDF link\n",
        "    for i, url in enumerate(pdf_urls):\n",
        "        file_name = f\"paper_{i+1}.pdf\"\n",
        "\n",
        "        # Download the PDF\n",
        "        download_pdf(url, file_name)\n",
        "\n",
        "        # Extract and display the requested sections\n",
        "        print(f\"\\nExtracted sections from {file_name}:\")\n",
        "        for section in selected_sections:\n",
        "            if section in available_sections:\n",
        "                extracted_text = extract_section_from_pdf(file_name, section)\n",
        "                extracted_data[section].append(extracted_text)\n",
        "                print(f\"\\n--- {section.capitalize()} ---\")\n",
        "                print(extracted_text)\n",
        "\n",
        "        # Summarize each extracted section\n",
        "        for section in selected_sections:\n",
        "            print(f\"\\n--- Summarizing {section.capitalize()} ---\")\n",
        "            combined_text = \" \".join(extracted_data[section])\n",
        "            summarized_text = summarize_long_text(combined_text)\n",
        "            print(summarized_text)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gTsDwx0HAIzo",
        "outputId": "3c3ba601-8f31-497d-aeef-2c8a8e7031d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Which sections do you want to extract? (Options: abstract, introduction, methods, results, literature review, conclusion, bibliography, future scope, limitations)\n",
            "Enter sections separated by commas: abstract\n",
            "\n",
            "Extracted sections from paper_1.pdf:\n",
            "\n",
            "--- Abstract ---\n",
            "Abstract—InNaturalLanguageProcessing(NLP),Self-supervisedLearning(SSL)andtransformersarealreadythemethodsof\n",
            "choiceduetothetremendoussuccessofattentionbasedself-supervisedtransformermodelslikeBERT[1]andGPT[2].Sofar,the\n",
            "visiontransformers,adoptedfromNLPtransformers,havebeenshowntoworkwellwhenpretrainedeitherusingalargescale\n",
            "superviseddata[3]orwithsomekindofco-supervision,e.g.intermsofteachernetwork[4].Thesesupervisedpretrainedvision\n",
            "transformersachieveoutstandingresultsindownstreamtaskswithminimalchanges[3],[4],[5].Self-supervisedPretraining(SSP)is\n",
            "stillnotthemethodofchoiceforcomputervisionduetoperformancegap[3],however,SSLisgainingincreasingtractionincomputer\n",
            "visionastheperformancegapbetweenSupervisedPretraining(SP)andSSPisreducingfordownstreamapplications,like\n",
            "classification,localisation,segmentation,etc.Self-supervisedvisionTransformers(SiT)isthefirstworkwhichestablishesthatSSP\n",
            "canoutperformSPfordownstreamapplications,establishingSSPasamoresuitablechoiceforpretrainingvisiontransformers.\n",
            "SiTisthefirstmaskedimagemodellingworkforvisiontransformers.AtitscoreSiTbuildstheideaofGroupMaskedModelLearning\n",
            "(GMML),asimplemaskedautoencoderframeworktoobtainapretextmodel.Thearchitecturalflexibilityofvisiontransformersallows\n",
            "ustouseSiTasanautoencoderandworkwithmultipleself-supervisedtasksseamlessly.Theproposedapproachisevaluatedon\n",
            "standarddatasetsusingcommonprotocols.TheresultsdemonstratethesuitabilityoftheGMMLframeworkforSSLandvision\n",
            "transformers.SiTconsistentlyoutperformssupervisedpretrainingaswellaspriorartswithalargemargin.Unlikeothervision\n",
            "transformerbasedpretrainingmethods,SiTperformsverystronglyonsmallandmediumscaledatasetsaswell.ThankstoSiT,the\n",
            "visiontransformerscanoutperform(performonparwith)ConvolutionalNeuralNetwork(CNN)counterpartforsmallandmedium\n",
            "datasetswithoutusinganyexternaldataforpretraining,overcomingtheproblemofdata-hungryvisiontransformers.Pretraining,\n",
            "finetuning,andevaluationcodesareavailableunder:https://github.com/Sara-Ahmed/SiT.\n",
            "Impact:WeproposedGMMLframeworkinSiTforself-supervisedlearningofvisiontransformersatthebeginningof2021using\n",
            "maskedautoencoderwithreconstructionloss,howevertheideaisgenerallyapplicabletootherlossesasshowninlaterstudies[6],[7],\n",
            "[8].AtthetimeofconceptionofSiT,themeritsofGMMLwereshownemployingsmallmodelsandsmall/mediumscaledatasetsdueto\n",
            "extremelyrestrictedcomputationalresources.Sincethen,GMMLhasbeenwidelyadoptedincomputervisionandotherrelatedfields.\n",
            "Towardstheendof2021,SIMMIM[9]andMAE[10]extendedGMMLwithreconstructionlossusinghugevisiontransformersonlarge\n",
            "scaledatasets,likeImageNet-1K[11].GMMLisnowtheleadingSSLframeworkonmultipleapplicationareas,givingsate-of-the-art\n",
            "resultsforimageclassification[7],segmentation[9],audioanalysis[12],medicalimageanalysis[13],[14],videorepresentation[15],\n",
            "etc.InshortMIM/GMMLisenablingthecomputervisioncommunitytoenjoythesamesuccessinSSLwhichNLPcommunityhas\n",
            "enjoyedforBERT.SiTperformsmuchbetterthanpriorartandpostartwhentrainedusingsmalltomediumscaledatasetwithoutany\n",
            "externaldataandperformsbetterthanpriorartandonparwithpostartwhichhaveadoptedGMMLframeworkwhenpretrainedon\n",
            "largescaledatasets.\n",
            "IndexTerms—MaskedImageModelling(MIM),Maskedautoencoders,GroupMaskedModelLearning(GMML),VisionTransformer,\n",
            "Self-supervisedLearning,DiscriminativeLearning,ImageClassification,Transformer-basedAutoencoders.\n",
            "(cid:70)\n",
            "1\n",
            "\n",
            "--- Summarizing Abstract ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-large and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-de6695242e74>\u001b[0m in \u001b[0;36m<cell line: 118>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-48-de6695242e74>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n--- Summarizing {section.capitalize()} ---\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcombined_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextracted_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msection\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0msummarized_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummarize_long_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummarized_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-de6695242e74>\u001b[0m in \u001b[0;36msummarize_long_text\u001b[0;34m(long_text, max_token_length)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;31m# Generate summary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0msummary_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_summary_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Decode summary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2062\u001b[0m             \u001b[0;31m# 14. run beam sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2063\u001b[0;31m             result = self._beam_search(\n\u001b[0m\u001b[1;32m   2064\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2065\u001b[0m                 \u001b[0mbeam_scorer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_beam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, generation_config, synced_gpus, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   3236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3237\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Unchanged original behavior\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3238\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3240\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msynced_gpus\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mthis_peer_finished\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/pegasus/modeling_pegasus.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1350\u001b[0m                 )\n\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1352\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m   1353\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/pegasus/modeling_pegasus.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1214\u001b[0;31m         decoder_outputs = self.decoder(\n\u001b[0m\u001b[1;32m   1215\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/pegasus/modeling_pegasus.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 )\n\u001b[1;32m   1045\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m   1047\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/pegasus/modeling_pegasus.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0;31m# cross_attn cached key/values tuple is at positions 3,4 of present_key_value tuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0mcross_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m             hidden_states, cross_attn_weights, cross_attn_present_key_value = self.encoder_attn(\n\u001b[0m\u001b[1;32m    426\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m                 \u001b[0mkey_value_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/pegasus/modeling_pegasus.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0msrc_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0mattn_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattn_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbsz\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}